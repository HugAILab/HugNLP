<p align="center">
    <br>
    <img src="images/logo.png" width="360"/>
    <br>
</p>
<p align="center" style="font-size:22px;"> <b> æ¬¢è¿ä½¿ç”¨HugNLPï¼ğŸ¤— æ‹¥æŠ±NLP! </b>
</p>


<div align="center">

[![CircleCI](https://dl.circleci.com/status-badge/img/gh/HugAILab/HugNLP/tree/main.svg?style=svg)](https://dl.circleci.com/status-badge/redirect/gh/HugAILab/HugNLP/tree/main)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/HugAILab/HugNLP.svg)](https://github.com/HugAILab/HugNLP/pull/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
[![arXiv](https://img.shields.io/badge/arXiv-2302.14286-b31b1b.svg)](https://arxiv.org/abs/2302.14286)
[[è‹±æ–‡](./README.md)]
    
</div>

# å…³äºHugNLP

HugNLPæ˜¯ä¸€ä¸ªåŸºäº[Hugging Face](https://huggingface.co/)å¼€å‘çš„å…¨é¢ç»Ÿä¸€çš„NLPå¼€æºæ¡†æ¶ã€‚
<!-- The founder and main developer is [Jianing Wang](https://wjn1996.github.io/). The collaborators are [Nuo Chen](https://github.com/nchen909), [Qiushi Sun](https://github.com/QiushiSun) and . -->

## **æœ€æ–°æ¶ˆæ¯

- ğŸ†• [23-05-05]: HugNLPå·²å‘å¸ƒäº@HugAILab !
- ğŸ†• [23-04-06]: ç±»ChatGPTèŠå¤©åŠ©æ‰‹HugChatä¸Šçº¿! æ¬¢è¿ä¸HugChatèŠå¤©! [[æ–‡æ¡£](./documents/instruction_prompting/generative_instruction_tuning.md)]
- ğŸ†• [23-04-02]: å¢åŠ GPTé£æ ¼çš„æŒ‡ä»¤è°ƒä¼˜ã€‚å¯æŒç»­è®­ç»ƒä¸€ä¸ªå°è§„æ¨¡çš„ChatGPT! [[æ–‡æ¡£](./documents/instruction_prompting/generative_instruction_tuning.md)]
- ğŸ†• [23-03-21]: å®Œæˆåºåˆ—åˆ†ç±»çš„GPT-styleæƒ…æ™¯å­¦ä¹ ã€‚ [[æ–‡æ¡£](./documents/instruction_prompting/incontext_learning_for_cls.md)]
- ğŸ†• [23-03-13]: å¢åŠ ä»£ç å…‹éš†æ£€æµ‹å’Œç¼ºé™·æ£€æµ‹ä»»åŠ¡ã€‚ç”¨æˆ·å¯è‡ªå®šä¹‰æ•°æ®é›†ç”¨æ¥è®­ç»ƒã€‚ [[æ–‡æ¡£](./documents/code/code_classification.md)]
- ğŸ†• [23-03-03]: æ·»åŠ HugIE APIå’Œç›¸åº”çš„è®­ç»ƒè„šæœ¬ã€‚ä½ å¯ä»¥ç”¨å®ƒå¯¹ä¸­æ–‡æ•°æ®è¿›è¡Œä¿¡æ¯æŠ½å–ã€‚ [[æ–‡æ¡£](./documents/information_extraction/HugIE.md)]
- ğŸ†• [23-02-18]: HugNLPé¡¹ç›®å·²å¼€æºï¼

# æ¶æ„

HugNLPæ¡†æ¶æ¦‚è§ˆå¦‚ä¸‹ï¼š

<p align="center">
    <br>
    <img src="images/overview.png" width="80%"/>
    <br>
<p>
### æ¨¡å‹ï¼ˆModelsï¼‰

åœ¨HugNLPä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€äº›æµè¡Œçš„åŸºäºtransformerçš„æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œå¦‚BERTã€RoBERTaã€GPT-2ç­‰ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†KP-PLMï¼Œä¸€ç§æ–°é¢–çš„çŸ¥è¯†å¢å¼ºå‹é¢„è®­ç»ƒèŒƒå¼ï¼Œå¯ç”¨äºæ³¨å…¥äº‹å®çŸ¥è¯†ï¼Œå¹¶å¯è½»æ¾ç”¨äºä»»æ„çš„PLMã€‚
é™¤äº†åŸºæœ¬çš„PLMsï¼Œæˆ‘ä»¬è¿˜å®ç°äº†ä¸€äº›ç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ï¼Œæ¶‰åŠåºåˆ—åˆ†ç±»ã€åŒ¹é…ã€æ ‡æ³¨ã€è¯å…ƒæŠ½å–ã€å¤šé¡¹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚
æˆ‘ä»¬åŒæ—¶å¼€å‘äº†æ ‡å‡†å¾®è°ƒï¼ˆåŸºäºåˆ†ç±»å¤´å’Œæç¤ºè°ƒä¼˜æ¨¡å‹ï¼‰ï¼Œä½¿PLMåœ¨åˆ†ç±»ä»»åŠ¡ä¸Šå¯è°ƒä¼˜ã€‚
å¯¹äºå°æ ·æœ¬å­¦ä¹ è®¾ç½®ï¼ŒHugNLPåœ¨å°æ ·æœ¬åˆ†ç±»å’Œå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ–¹é¢éƒ½æä¾›äº†ä¸€ä¸ªåŸå‹ç½‘ç»œã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åœ¨HugNLPä¸­åŠ å…¥äº†ä¸€äº›å³æ’å³ç”¨çš„å·¥å…·ã€‚

1. å‚æ•°å†»ç»“ï¼šå¦‚æœæˆ‘ä»¬æƒ³è¿›è¡Œå‚æ•°æœ‰æ•ˆæ€§å­¦ä¹ ï¼Œå†»ç»“PLMä¸­çš„ä¸€äº›å‚æ•°ä»¥æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®`use_freezing`ï¼Œå¹¶å†»ç»“éª¨å¹²æ¨¡å‹ã€‚
2. ä¸ç¡®å®šæ€§ä¼°è®¡ï¼šç›®çš„æ˜¯åœ¨åŠç›‘ç£å­¦ä¹ ä¸­è®¡ç®—æ¨¡å‹çš„ç¡®å®šæ€§ã€‚
3. é¢„æµ‹æ ¡å‡†ï¼šå¯ä»¥é€šè¿‡æ ¡å‡†åˆ†å¸ƒåŠç¼“è§£è¯­ä¹‰åå·®é—®é¢˜æ¥è¿›ä¸€æ­¥æé«˜å‡†ç¡®æ€§ã€‚

### å¤„ç†å™¨ï¼ˆProcessorsï¼‰

å¤„ç†å™¨æ—¨åœ¨åŠ è½½æ•°æ®é›†ï¼Œå¹¶åœ¨ä¸€ä¸ªåŒ…å«å¥å­æ¬¡å…ƒåŒ–ã€é‡‡æ ·å’Œå¼ é‡ç”Ÿæˆçš„æµæ°´çº¿ä¸­å¤„ç†ä»»åŠ¡çš„examplesã€‚
ç”¨æˆ·ä¹Ÿå¯ä»¥ç›´æ¥é€šè¿‡`load_dataset`è·å¾—æ•°æ®ï¼Œå³å¯ä»¥ä»äº’è”ç½‘ä¸Šç›´æ¥ä¸‹è½½æˆ–ä»æœ¬åœ°ç£ç›˜ä¸ŠåŠ è½½ã€‚
å¯¹ä¸åŒçš„ä»»åŠ¡ï¼Œç”¨æˆ·åº”è¯¥å®šä¹‰ä¸€ä¸ªä»»åŠ¡ç‰¹å®šçš„æ•°æ®æ•´ç†å™¨ï¼ˆdata collatorï¼‰ï¼Œå…¶ç›®çš„æ˜¯å°†åŸå§‹å®ä¾‹ï¼ˆexamplesï¼‰è½¬åŒ–ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡featuresï¼ˆç‰¹å¾ï¼‰ã€‚

### åº”ç”¨ï¼ˆApplicationsï¼‰

åº”ç”¨ä¸ºç”¨æˆ·æä¾›äº†ä¸°å¯Œçš„æ¨¡å—ï¼Œé€šè¿‡åœ¨æ¨¡å‹å’Œå¤„ç†å™¨çš„ä¸€ç³»åˆ—è®¾ç½®ä¸­è¿›è¡Œé€‰æ‹©ï¼Œå»ºç«‹ç°å®ä¸–ç•Œçš„åº”ç”¨å’Œäº§å“ã€‚

# æ ¸å¿ƒåŠŸèƒ½

æˆ‘ä»¬æä¾›ä¸€äº›æ ¸å¿ƒèƒ½åŠ›æ¥æ”¯æŒNLPçš„ä¸‹æ¸¸åº”ç”¨ã€‚

### çŸ¥è¯†å¢å¼ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹

ä¼ ç»Ÿçš„é¢„è®­ç»ƒæ–¹æ³•ç¼ºä¹äº‹å®æ€§çŸ¥è¯†ã€‚
ä¸ºäº†å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†KP-PLMï¼Œå®ƒæœ‰ä¸€ä¸ªæ–°é¢–çš„çŸ¥è¯†æç¤ºèŒƒå¼ï¼Œç”¨äºçŸ¥è¯†å¢å¼ºçš„é¢„è®­ç»ƒã€‚
å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡è¯†åˆ«å®ä½“ä¸ºæ¯ä¸ªè¾“å…¥æ–‡æœ¬æ„å»ºä¸€ä¸ªçŸ¥è¯†å­å›¾ï¼Œå¹¶ä¸çŸ¥è¯†åº“å¯¹é½ï¼Œç„¶åå°†è¿™ä¸ªå­å›¾åˆ†è§£ä¸ºå¤šä¸ªå…³ç³»è·¯å¾„ï¼Œè¿™äº›å…³ç³»è·¯å¾„å¯ä»¥ç›´æ¥è½¬åŒ–ä¸ºè¯­è¨€æç¤ºã€‚

### åŸºäºæç¤ºçš„å¾®è°ƒ

åŸºäºæç¤ºçš„å¾®è°ƒæ—¨åœ¨é‡ç”¨é¢„è®­ç»ƒç›®æ ‡ä»»åŠ¡ï¼ˆå¦‚æ©ç è¯­è¨€å»ºæ¨¡ã€å› æœè¯­è¨€å»ºæ¨¡ï¼‰ï¼Œå¹¶åˆ©ç”¨è®¾è®¡å¥½çš„templateå’Œverbalizerè¿›è¡Œé¢„æµ‹ï¼Œè¿™åœ¨ä½èµ„æºç¯å¢ƒä¸‹é¢‡æœ‰æˆæ•ˆã€‚
æˆ‘ä»¬ä¹Ÿå°†ä¸€äº›æ–°æ–¹æ³•æ•´åˆåˆ°HugNLPä¸­ï¼Œå¦‚PETã€P-Tuningç­‰ã€‚

### æŒ‡ä»¤è°ƒä¼˜å’Œæƒ…æ™¯å­¦ä¹ 

æŒ‡ä»¤è°ƒä¼˜å’Œæƒ…æ™¯å­¦ä¹ å¯ä»¥åœ¨ä¸æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹è¿›è¡Œå°æ ·æœ¬å’Œé›¶æ ·æœ¬å­¦ä¹ ï¼Œå…¶ç›®çš„æ˜¯å°†ä»»åŠ¡ç›¸å…³çš„æŒ‡ä»¤æˆ–æ¼”ç¤ºç¤ºä¾‹ä¸²è”èµ·æ¥ï¼Œä¿ƒä½¿GPT-style PLMäº§ç”Ÿå¯é çš„ååº”ã€‚
å› æ­¤ï¼Œæ‰€æœ‰çš„NLPä»»åŠ¡éƒ½å¯ä»¥è¢«ç»Ÿä¸€åˆ°ç›¸åŒçš„æ ¼å¼ä¸­ï¼Œå¹¶å¤§å¹…æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
åœ¨è¯¥æƒ³æ³•çš„å¯å‘ä¸‹ï¼Œæˆ‘ä»¬æŠŠå®ƒæ‰©å±•åˆ°å…¶ä»–å‡ ä¸ªèŒƒå¼ï¼š

1.æŠ½å–å¼èŒƒå¼ï¼šæˆ‘ä»¬å°†å„ç§NLPä»»åŠ¡ç»Ÿä¸€ä¸ºè¯å…ƒæŠ½å–ï¼Œè¿™ä¸æŠ½å–å¼é—®é¢˜å›ç­”ç›¸åŒã€‚
2.æ¨ç†å¼èŒƒå¼ï¼šæ‰€æœ‰çš„ä»»åŠ¡éƒ½å¯ä»¥è¢«è§†ä¸ºè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œä»¥åŒ¹é…è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å…³ç³»ã€‚
3.ç”Ÿæˆå¼èŒƒå¼ï¼šæˆ‘ä»¬å°†æ‰€æœ‰çš„ä»»åŠ¡ç»Ÿä¸€ä¸ºè‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰ï¼Œå¹¶åŸºäºæŒ‡ä»¤è°ƒä¼˜ã€æƒ…æ™¯å­¦ä¹ æˆ–æ€ç»´é“¾æ¥è®­ç»ƒå› æœæ¨¡å‹ã€‚

### ä¸ç¡®å®šæ€§ä¼°è®¡çš„è‡ªè®­ç»ƒ

è‡ªè®­ç»ƒå¯ä»¥é€šè¿‡åˆ©ç”¨å¤§è§„æ¨¡çš„æœªæ ‡è®°æ•°æ®æ¥è§£å†³æ ‡è®°æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯åŠç›‘ç£å­¦ä¹ ä¸­çš„ä¸€ä¸ªæˆç†ŸèŒƒå¼ã€‚
ç„¶è€Œï¼Œæ ‡å‡†çš„è‡ªè®­ç»ƒå¯èƒ½ä¼šäº§ç”Ÿè¿‡å¤šçš„å™ªéŸ³ï¼Œä¸å¯é¿å…åœ°ä¼šå› ä¸ºç¡®è®¤åå·®è€Œé™ä½æ¨¡å‹çš„æ€§èƒ½ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„è‡ªè®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨å°‘æ•°æ ‡ç­¾æ•°æ®ä¸Šè®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œç„¶ååœ¨è´å¶æ–¯ç¥ç»ç½‘ç»œï¼ˆBNNï¼‰ä¸­ä½¿ç”¨è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰dropoutæŠ€æœ¯æ¥è¿‘ä¼¼ä¼°è®¡æ¨¡å‹çš„ç¡®å®šæ€§ï¼Œå¹¶é€‰æ‹©æ•™å¸ˆæ¨¡å‹ç¡®å®šæ€§è¾ƒé«˜çš„ä¾‹å­ã€‚

### å‚æ•°æœ‰æ•ˆæ€§å­¦ä¹ 

ä¸ºæé«˜HugNLPçš„è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬è¿˜å®ç°äº†å‚æ•°æœ‰æ•ˆæ€§å­¦ä¹ ï¼Œå…¶ç›®çš„æ˜¯å°†ä¸€äº›å‚æ•°å†»ç»“åœ¨éª¨å¹²ç½‘ç»œä¸­ï¼Œè¿™æ ·æˆ‘ä»¬åœ¨æ¨¡å‹è®­ç»ƒä¸­åªéœ€è°ƒæ•´å°‘æ•°å‚æ•°ã€‚
æˆ‘ä»¬å¼€å‘äº†ä¸€äº›æ–°çš„å‚æ•°æ•ˆç‡å­¦ä¹ æ–¹æ³•ï¼Œå¦‚Prefix-tuningã€Adapter-Tuningã€BitFitå’ŒLoRAç­‰ã€‚

# å®‰è£…

> git clone https://github.com/HugAILab/HugNLP.git
>
> cd HugNLP
>
> python3 setup.py install

ç›®å‰ï¼Œè¯¥é¡¹ç›®ä»åœ¨å¼€å‘å’Œæ”¹è¿›ä¸­ï¼Œä½¿ç”¨è¿‡ç¨‹ä¸­å¯èƒ½ä¼šæœ‰ä¸€äº›bugsï¼Œè¯·è°…è§£ã€‚æˆ‘ä»¬ä¹ŸæœŸå¾…ç€ä½ èƒ½æå‡ºissuesæˆ–pull requestsã€‚

# é¢„å»ºåº”ç”¨æ¦‚è§ˆ

æˆ‘ä»¬åœ¨HugNLPä¸­æ¼”ç¤ºäº†æ‰€æœ‰é¢„å»ºçš„åº”ç”¨ã€‚ä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªåº”ç”¨æ¥ä½¿ç”¨HugNLPï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹è¯¦ç»†çš„æ–‡ä»¶ã€‚

| **åº”ç”¨**           | **è¿è¡Œä»»åŠ¡**                  | **ä»»åŠ¡ç¬”è®°**                                                 | **é¢„è®­ç»ƒæ¨¡å‹**                          | **æ–‡æ¡£**                                                     |
| ------------------ | ----------------------------- | ------------------------------------------------------------ | --------------------------------------- | ------------------------------------------------------------ |
| **é»˜è®¤åº”ç”¨**       | run_seq_cls.sh                | **ç›®æ ‡**: ç”¨æˆ·è‡ªå®šä¹‰æ•°æ®ä¸‹åºåˆ—åˆ†ç±»çš„æ ‡å‡† **å¾®è°ƒ** æˆ– **æç¤ºè°ƒä¼˜**  <br> **è·¯å¾„**: applications/default_applications | BERT, RoBERTa, DeBERTa                  | [æŸ¥çœ‹](./documents/default_tasks/default_sequence_classification.md) |
|                    | run_seq_labeling.sh           | **ç›®æ ‡**: ç”¨æˆ·è‡ªå®šä¹‰æ•°æ®ä¸‹åºåˆ—æ ‡æ³¨çš„æ ‡å‡† **å¾®è°ƒ**  <br> **è·¯å¾„**: applications/default_applications | BERT, RoBERTa, ALBERT                   |                                                              |
| **é¢„è®­ç»ƒ**         | run_pretrain_mlm.sh           | **ç›®æ ‡**: é€šè¿‡**æ©ç è¯­è¨€å»ºæ¨¡**(MLM)çš„é¢„è®­ç»ƒ <br> **è·¯å¾„**: applications/pretraining/ | BERT, RoBERTa                           | [æŸ¥çœ‹](./documents/pretraining/Masked%20LM%20for%20Continual%20Pre-training.md) |
|                    | run_pretrain_casual_lm.sh     | **ç›®æ ‡**: é€šè¿‡**å› æœè¯­è¨€å»ºæ¨¡** (CLM)çš„é¢„è®­ç»ƒ <br> **è·¯å¾„**: applications/pretraining | BERT, RoBERTa                           | [æŸ¥çœ‹](./documents/pretraining/Causal%20LM%20for%20Continual%20Pre-training.md) |
| **GLUE Benchmark** | run_glue.sh                   | **ç›®æ ‡**: GLUEåˆ†ç±»ä»»åŠ¡çš„æ ‡å‡† **å¾®è°ƒ** æˆ– **æç¤ºè°ƒä¼˜** <br> **è·¯å¾„**: applications/benchmark/glue | BERT, RoBERTa, DeBERTa                  |                                                              |
|                    | run_causal_incontext_glue.sh  | **ç›®æ ‡**: GLUEåˆ†ç±»ä»»åŠ¡çš„**ä¸Šä¸‹æ–‡å­¦ä¹ ** <br> **è·¯å¾„**: applications/benchmark/glue | GPT-2                                   |                                                              |
| **CLUE Benchmark** | clue_finetune_dev.sh          | **ç›®æ ‡**: GLUEåˆ†ç±»ä»»åŠ¡çš„æ ‡å‡† **å¾®è°ƒ** æˆ– **æç¤ºè°ƒä¼˜**  <br> **è·¯å¾„**: applications/benchmark/clue | BERT, RoBERTa, DeBERTa                  |                                                              |
|                    | run_clue_cmrc.sh              | **ç›®æ ‡**: CLUE CMRC2018ä»»åŠ¡çš„æ ‡å‡† **å¾®è°ƒ** <br> **è·¯å¾„**: applications/benchmark/cluemrc | BERT, RoBERTa, DeBERTa                  |                                                              |
|                    | run_clue_c3.sh                | **ç›®æ ‡**: CLUE C3ä»»åŠ¡çš„æ ‡å‡† **å¾®è°ƒ** <br> **è·¯å¾„**: applications/benchmark/cluemrc | BERT, RoBERTa, DeBERTa                  |                                                              |
|                    | run_clue_chid.sh              | **ç›®æ ‡**: CLUE CHIDä»»åŠ¡çš„æ ‡å‡† **å¾®è°ƒ**<br> **è·¯å¾„**: applications/benchmark/cluemrc | BERT, RoBERTa, DeBERTa                  |                                                              |
| **æŒ‡ä»¤è°ƒä¼˜**       | run_causal_instruction.sh     | **ç›®æ ‡**: é€šè¿‡åŸºäºå› æœé¢„è®­ç»ƒæ¨¡å‹çš„ç”Ÿæˆå¼æŒ‡ä»¤è°ƒä¼˜è¿›è¡Œ**è·¨ä»»åŠ¡è®­ç»ƒ**. <font color='red'>**ä½ å¯ç”¨æ¥è®­ç»ƒä¸€ä¸ªå°å‹çš„ChatGPT**</font>. <br> **è·¯å¾„**: applications/instruction_prompting/instruction_tuning | GPT2                                    | [æŸ¥çœ‹](./documents/instruction_prompting/generative_instruction_tuning.md) |
|                    | run_zh_extract_instruction.sh | **ç›®æ ‡**: é€šè¿‡åŸºäºGlobal Pointeræ¨¡å‹çš„æŠ½å–å¼æŒ‡ä»¤è°ƒä¼˜è¿›è¡Œ**è·¨ä»»åŠ¡è®­ç»ƒ** <br> **è·¯å¾„**: applications/instruction_prompting/chinese_instruction | BERT, RoBERTa, DeBERTa                  | [æŸ¥çœ‹](./documents/instruction_prompting/extractive_instruction_tuning.md) |
|                    | run_causal_incontext_cls.sh   | **ç›®æ ‡**: ç”¨æˆ·è‡ªå®šä¹‰åˆ†ç±»ä»»åŠ¡ä¸‹çš„**ä¸Šä¸‹æ–‡å­¦ä¹ ** <br> **è·¯å¾„**: applications/instruction_prompting/incontext_learning | GPT-2                                   | [æŸ¥çœ‹](./documents/instruction_prompting/incontext_learning_for_cls.md) |
| **ä¿¡æ¯æŠ½å–**       | run_extractive_unified_ie.sh  | **ç›®æ ‡**: **HugIE**: é€šè¿‡æŠ½å–å¼æŒ‡ä»¤è°ƒä¼˜è®­ç»ƒä¸€ä¸ªç»Ÿä¸€çš„ä¸­æ–‡ä¿¡æ¯æŠ½å–åº”ç”¨. <br> **è·¯å¾„**: applications/information_extraction/HugIE | BERT, RoBERTa, DeBERTa                  | [æŸ¥çœ‹](./documents/information_extraction/HugIE.md)          |
|                    | api_test.py                   | **ç›®æ ‡**: HugIE: APIæµ‹è¯•. <br> **è·¯å¾„**: applications/information_extraction/HugIE | -                                       | [æŸ¥çœ‹](./documents/information_extraction/HugIE.md)          |
|                    | run_fewnerd.sh                | **ç›®æ ‡**: ç”¨äºå‘½åå®ä½“è¯†åˆ«çš„**åŸå‹å­¦ä¹ **, åŒ…æ‹¬ SpanProto, TokenProto <br> **è·¯å¾„**: applications/information_extraction/fewshot_ner | BERT                                    |                                                              |
| **ä»£ç ç†è§£ä»»åŠ¡**   | run_clone_cls.sh              | **ç›®æ ‡**: ç”¨äºä»£ç å…‹éš†æ£€æµ‹ä»»åŠ¡çš„æ ‡å‡†**å¾®è°ƒ** <br> **è·¯å¾„**: applications/code/code_clone | CodeBERT, CodeT5, GraphCodeBERT, PLBART | [æŸ¥çœ‹](./documents/code/code_classification.md)              |
|                    | run_defect_cls.sh             | **ç›®æ ‡**: ç”¨äºç¼ºé™·æ£€æµ‹ä»»åŠ¡çš„æ ‡å‡†**å¾®è°ƒ** <br> **è·¯å¾„**: applications/code/code_defect | CodeBERT, CodeT5, GraphCodeBERT, PLBART | [æŸ¥çœ‹](./documents/code/code_classification.md)              |

æ›´å¤šå…³äºé¢„å»ºåº”ç”¨ä»¥åŠæ¨¡å‹å’Œå¤„ç†å™¨è®¾ç½®çš„ç»†èŠ‚å¯ä»¥åœ¨[HugNLPæ–‡æ¡£](./documents/README.md)ä¸­æ‰¾åˆ°ã€‚

# å¿«é€Ÿä¸Šæ‰‹

è¿™é‡Œæˆ‘ä»¬æä¾›ä¸€ä¸ªä¾‹å­æ¥å‘Šè¯‰ä½ å¦‚ä½•å¿«é€Ÿä½¿ç”¨HugNLPã€‚
å¦‚æœä½ æƒ³åœ¨ç”¨æˆ·å®šä¹‰çš„æ•°æ®é›†ä¸Šæ‰§è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œä½ å¯ä»¥åœ¨ä¸€ä¸ªç›®å½•ä¸Šå‡†å¤‡ä¸‰ä¸ªjsonæ–‡ä»¶ (``train.json``, ``dev.json``, ``test.json``)ï¼Œç„¶åè¿è¡Œä»¥ä¸‹è„šæœ¬æ–‡ä»¶

> bash ./application/default_applications/run_seq_cls.sh

åœ¨å®éªŒä¹‹å‰ï¼Œä½ éœ€è¦åœ¨è„šæœ¬æ–‡ä»¶``run_seq_cls.sh``ä¸­å®šä¹‰ä»¥ä¸‹å‚æ•°ã€‚

- --model_name_or_path: é¢„è®­ç»ƒçš„æ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œä¾‹å¦‚ï¼šbert-base-uncasedã€‚
- --data_path: æ•°æ®é›†çš„è·¯å¾„ï¼ˆåŒ…æ‹¬`train.json`ï¼Œ`dev.json`å’Œ`test.json`ï¼‰ï¼Œä¾‹å¦‚ï¼š`./datasets/data_example/cls/`ã€‚
- --user_defined: å¦‚æœæ²¡æœ‰`label_names.txt`ï¼Œä½ éœ€è¦å®šä¹‰æ ‡ç­¾åç§°ã€‚

å¦‚æœä½ æƒ³è¿›è¡ŒåŸºäºæç¤ºçš„å¾®è°ƒï¼Œä½ å¯ä»¥æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼š

- --use_prompt_for_cls
- ---task_type: one of ``masked_prompt_cls``, ``masked_prompt_prefix_cls``,``masked_prompt_ptuning_cls``, ``masked_prompt_adapter_cls``.

ä½ éœ€è¦æ·»åŠ  ``template.json`` å’Œ ``label_words_mapping.json``æ–‡ä»¶.

å¦‚æœä½ æƒ³ä½¿ç”¨å‚æ•°æœ‰æ•ˆæ€§å­¦ä¹ ï¼Œä½ å¯ä»¥æ·»åŠ ä»¥ä¸‹å‚æ•°ï¼š

- --use_freezing

ä»¥``run_seq_cls.sh`` ä¸ºä¾‹:

```bash
path=chinese-macbert-base
MODEL_TYPE=bert
data_path=/wjn/frameworks/HugNLP/datasets/data_example/cls
TASK_TYPE=head_cls
len=196
bz=4
epoch=10
eval_step=50
wr_step=10
lr=1e-05

export CUDA_VISIBLE_DEVICES=0,1
python3 -m torch.distributed.launch --nproc_per_node=2 --master_port=6014 hugnlp_runner.py \
--model_name_or_path=$path \
--data_dir=$data_path \
--output_dir=./outputs/default/sequence_classification\
--seed=42 \
--exp_name=default-cls \
--max_seq_length=$len \
--max_eval_seq_length=$len \
--do_train \
--do_eval \
--do_predict \
--per_device_train_batch_size=$bz \
--per_device_eval_batch_size=4 \
--gradient_accumulation_steps=1 \
--evaluation_strategy=steps \
--learning_rate=$lr \
--num_train_epochs=$epoch \
--logging_steps=100000000 \
--eval_steps=$eval_step \
--save_steps=$eval_step \
--save_total_limit=1 \
--warmup_steps=$wr_step \
--load_best_model_at_end \
--report_to=none \
--task_name=default_cls \
--task_type=$TASK_TYPE \
--model_type=$MODEL_TYPE \
--metric_for_best_model=acc \
--pad_to_max_length=True \
--remove_unused_columns=False \
--overwrite_output_dir \
--fp16 \
--label_names=labels \
--keep_predict_labels \
--user_defined="label_names=entailment,neutral,contradiction"
```

# å¿«é€Ÿå¼€å‘

æœ¬èŠ‚æ˜¯ä¸ºå¼€å‘äººå‘˜å‡†å¤‡çš„ã€‚
HugNLPå¾ˆå®¹æ˜“ä½¿ç”¨å’Œå¼€å‘ã€‚æˆ‘ä»¬åœ¨ä¸‹å›¾ä¸­ç”»äº†ä¸€ä¸ªå·¥ä½œæµç¨‹ï¼Œä»¥æ˜¾ç¤ºå¦‚ä½•å¼€å‘ä¸€ä¸ªæ–°çš„è¿è¡Œä»»åŠ¡ã€‚

<p align="center">
    <br>
    <img src="images/workflow.png" width="90%"/>
    <br>
</p>
å®ƒå«æœ‰äº”ä¸ªä¸»è¦æ­¥éª¤ï¼ŒåŒ…æ‹¬åº“çš„å®‰è£…ã€æ•°æ®å‡†å¤‡ã€å¤„ç†å™¨é€‰æ‹©æˆ–è®¾è®¡ã€æ¨¡å‹é€‰æ‹©æˆ–è®¾è®¡ä»¥åŠåº”ç”¨è®¾è®¡ã€‚
è¿™è¯´æ˜HugNLPå¯ä»¥ç®€åŒ–å¤æ‚NLPæ¨¡å‹å’Œä»»åŠ¡çš„å®æ–½ã€‚

# é¢„å»ºäº§å“

ä¸‹é¢æˆ‘ä»¬å±•ç¤ºäº†ä¸¤ä¸ªé¢„å»ºAPIåº”ç”¨çš„ä¾‹å­ã€‚ 

### HugChatï¼š é¢å‘ç”Ÿæˆå¼æŒ‡ä»¤è°ƒä¼˜çš„ç±»ChatGPT PLMs

HugChatæ˜¯ä¸€ä¸ªç±»ChatGPTçš„å°æ¨¡å‹ï¼ŒåŸºäºç”Ÿæˆå¼æŒ‡ä»¤è°ƒä¼˜ï¼Œæ—¨åœ¨å°†æ‰€æœ‰NLPä»»åŠ¡ç»Ÿä¸€ä¸ºç”Ÿæˆæ ¼å¼æ¥è®­ç»ƒå› æœè¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT2ã€BARTï¼‰ã€‚
ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨HugNLPæ¥è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œå¹¶åœ¨ç”¨æˆ·å®šä¹‰çš„ç‰¹å®šä»»åŠ¡è¯­æ–™ä¸ŠæŒç»­è®­ç»ƒä¸€ä¸ªå°å‹çš„ç±»ChatGPTæ¨¡å‹ã€‚

ä½ å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸HugChatèŠå¤©ï¼š
> python3 applications/instruction_prompting/HugChat/hugchat.py



![image](./images/hugchat_hello.jpg)

<details><summary><b>1. å†™æ•…äº‹</b></summary>

![image](./images/hugchat_story.jpg)

</details>

<details><summary><b>2. å†™ä¿¡</b></summary>

![image](./images/hugchat_letter.jpg)

</details>

<details><summary><b>3. è®¡ç®—</b></summary>

![image]()

</details>

<details><summary><b>4. è‡ªç„¶è¯­è¨€ç†è§£ (æƒ…æ„Ÿ, é˜…è¯»ç†è§£, KBQA)</b></summary>

![image](./images/hugchat_nlu.jpg)

</details>

<details><summary><b>5. æœç´¢</b></summary>

![image](./images/hugchat_search.jpg)

</details>

<details><summary><b>6. å†™ä»£ç </b></summary>

![image](./images/hugchat_code.jpg)

</details>


ç¥ç©å¾—æ„‰å¿«ï¼æ›´å¤šçš„ç»†èŠ‚å¯ä»¥åœ¨[è¿™é‡Œ](./documents/instruction_prompting/generative_instruction_tuning.md)æ‰¾åˆ°ã€‚

### HugIEï¼šé€šè¿‡æŠ½å–å¼MRCå’ŒæŒ‡ä»¤è°ƒä¼˜çš„ç»Ÿä¸€ä¸­æ–‡ä¿¡æ¯æŠ½å–åº”ç”¨

ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰æ—¨åœ¨ä»éç»“æ„æ€§æ–‡æœ¬ä¸­æå–ç»“æ„çŸ¥è¯†ã€‚ç»“æ„çŸ¥è¯†æ˜¯ç”±""(head_entity, relation, tail_entity)""ç»„æˆçš„ä¸‰å…ƒç»„ã€‚IEç”±ä»¥ä¸‹ä¸¤ä¸ªä¸»è¦ä»»åŠ¡ç»„æˆï¼š

- å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ï¼šæ—¨åœ¨æå–ä¸€ç§ç±»å‹çš„æ‰€æœ‰å®ä½“ã€‚
- å…³ç³»æŠ½å–ï¼ˆREï¼‰ã€‚å®ƒæœ‰ä¸¤ç§ç›®æ ‡ï¼Œç¬¬ä¸€ç§ç›®æ ‡æ˜¯å¯¹ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»è¿›è¡Œåˆ†ç±»ï¼Œç¬¬äºŒç§ç›®æ ‡æ˜¯åœ¨ç»™å®šä¸€ä¸ªå¤´å®ä½“å’Œç›¸åº”çš„å…³ç³»æ—¶é¢„æµ‹å°¾å®ä½“ã€‚

æˆ‘ä»¬å°†NERå’ŒREçš„ä»»åŠ¡ç»Ÿä¸€åˆ°æŠ½å–å¼é—®é¢˜å›ç­”ï¼ˆå³æœºå™¨é˜…è¯»ç†è§£ï¼‰çš„èŒƒå¼ä¸­ã€‚
æˆ‘ä»¬ä¸ºNERå’ŒREè®¾è®¡äº†ç‰¹å®šä»»åŠ¡çš„æŒ‡ä»¤å’Œè¯­è¨€æç¤ºã€‚

> NER ä»»åŠ¡:
>
> - instruction: "æ‰¾åˆ°æ–‡ç« ä¸­æ‰€æœ‰ã€{entity_type}ã€‘ç±»å‹çš„å®ä½“ï¼Ÿæ–‡ç« ï¼šã€{passage_text}ã€‘"
>
> RE ä»»åŠ¡:
>
> - instruction: "æ‰¾åˆ°æ–‡ç« ä¸­ã€{head_entity}ã€‘çš„ã€{relation}ã€‘ï¼Ÿæ–‡ç« ï¼šã€{passage_text}ã€‘"

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨Global Pointerå’ŒChines-Macbertä½œä¸ºåŸºæœ¬æ¨¡å‹ã€‚

æˆ‘ä»¬çš„æ¨¡å‹ä¿å­˜åœ¨Hugging Faceä¸­: [https://huggingface.co/wjn1996/wjn1996-hugnlp-hugie-large-zh](https://huggingface.co/wjn1996/wjn1996-hugnlp-hugie-large-zh).

å¿«é€Ÿä½¿ç”¨HugIEè¿›è¡Œä¸­æ–‡ä¿¡æ¯æŠ½å–ï¼š

```python
from applications.information_extraction.HugIE.api_test import HugIEAPI
model_type = "bert"
hugie_model_name_or_path = "wjn1996/wjn1996-hugnlp-hugie-large-zh"
hugie = HugIEAPI("bert", hugie_model_name_or_path)
text = "å¤®å¹¿ç½‘åŒ—äº¬2æœˆ23æ—¥æ¶ˆæ¯ æ®ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®šï¼Œ2æœˆ23æ—¥8æ—¶37åˆ†åœ¨å¡”å‰å…‹æ–¯å¦å‘ç”Ÿ7.2çº§åœ°éœ‡ï¼Œéœ‡æºæ·±åº¦10å…¬é‡Œï¼Œéœ‡ä¸­ä½äºåŒ—çº¬37.98åº¦ï¼Œä¸œç»73.29åº¦ï¼Œè·æˆ‘å›½è¾¹å¢ƒçº¿æœ€è¿‘çº¦82å…¬é‡Œï¼Œåœ°éœ‡é€ æˆæ–°ç–†å–€ä»€ç­‰åœ°éœ‡æ„Ÿå¼ºçƒˆã€‚"

entity = "å¡”å‰å…‹æ–¯å¦åœ°éœ‡"
relation = "éœ‡æºä½ç½®"
predictions, topk_predictions = hugie.request(text, entity, relation=relation)
print("entity:{}, relation:{}".format(entity, relation))
print("predictions:\n{}".format(predictions))
print("topk_predictions:\n{}".format(predictions))
print("\n\n")

"""
# äº‹ä»¶ä¿¡æ¯è¾“å‡ºç»“æœï¼š
entity:å¡”å‰å…‹æ–¯å¦åœ°éœ‡, relation:éœ‡æºä½ç½®
predictions:
{0: ["10å…¬é‡Œ", "è·æˆ‘å›½è¾¹å¢ƒçº¿æœ€è¿‘çº¦82å…¬é‡Œ", "åŒ—çº¬37.98åº¦ï¼Œä¸œç»73.29åº¦", "åŒ—çº¬37.98åº¦ï¼Œä¸œç»73.29åº¦ï¼Œè·æˆ‘å›½è¾¹å¢ƒçº¿æœ€è¿‘çº¦82å…¬é‡Œ"]}
topk_predictions:
{0: [{"answer": "10å…¬é‡Œ", "prob": 0.9895901083946228, "pos": [(80, 84)]}, {"answer": "è·æˆ‘å›½è¾¹å¢ƒçº¿æœ€è¿‘çº¦82å…¬é‡Œ", "prob": 0.8584909439086914, "pos": [(107, 120)]}, {"answer": "åŒ—çº¬37.98åº¦ï¼Œä¸œç»73.29åº¦", "prob": 0.7202121615409851, "pos": [(89, 106)]}, {"answer": "åŒ—çº¬37.98åº¦ï¼Œä¸œç»73.29åº¦ï¼Œè·æˆ‘å›½è¾¹å¢ƒçº¿æœ€è¿‘çº¦82å…¬é‡Œ", "prob": 0.11628123372793198, "pos": [(89, 120)]}]}
"""

entity = "å¡”å‰å…‹æ–¯å¦åœ°éœ‡"
relation = "æ—¶é—´"
predictions, topk_predictions = hugie.request(text, entity, relation=relation)
print("entity:{}, relation:{}".format(entity, relation))
print("predictions:\n{}".format(predictions))
print("topk_predictions:\n{}".format(predictions))
print("\n\n")

"""
# äº‹ä»¶ä¿¡æ¯è¾“å‡ºç»“æœï¼š
entity:å¡”å‰å…‹æ–¯å¦åœ°éœ‡, relation:æ—¶é—´
predictions:
{0: ["2æœˆ23æ—¥8æ—¶37åˆ†"]}
topk_predictions:
{0: [{"answer": "2æœˆ23æ—¥8æ—¶37åˆ†", "prob": 0.9999995231628418, "pos": [(49, 59)]}]}
"""
```

# è´¡çŒ®è€…

<a href="https://github.com/HugAILab/HugNLP/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=HugAILab/HugNLP" />
</a>


# è”ç³»æˆ‘ä»¬

å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œä½ å¯ä»¥åŠ å…¥é’‰é’‰å°ç»„ï¼š

<p align="center">
    <br>
    <img src="images/dingding.jpg" width="250"/>
    <br>
</p>

æˆ–ç›´æ¥è”ç³»ä½œè€… [`ç‹å˜‰å®`](https://wjn1996.github.io).

# å¼•ç”¨

å¦‚æœä½ è§‰å¾—è¿™ä¸ªèµ„æºåº“æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```latex
@misc{wang2023hugnlp,
  doi       = {10.48550/ARXIV.2302.14286},
  url       = {https://arxiv.org/abs/2302.14286},
  author    = {Jianing Wang, Nuo Chen, Qiushi Sun, Wenkang Huang, Chengyu Wang, Ming Gao},
  title     = {HugNLP: A Unified and Comprehensive Library for Natural Language Processing},
  year      = {2023}
}
```

# å‚è€ƒæ–‡çŒ®

1. Jianing Wang, Nuo Chen, Qiushi Sun, Wenkang Huang, Chengyu Wang, Ming Gao:
HugNLP: A Unified and Comprehensive Library for Natural Language Processing. CoRR abs/2302.14286 (2023)
2. Jianing Wang, Wenkang Huang, Minghui Qiu, Qiuhui Shi, Hongbin Wang, Xiang Li, Ming Gao:
   Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding. EMNLP 2022: 3164-3177
3. Chengyu Wang, Jianing Wang, Minghui Qiu, Jun Huang, Ming Gao: TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification. EMNLP 2021: 2792-2802
4. Jianing Wang, Chengyu Wang, Jun Huang, Ming Gao, Aoying Zhou: Uncertainty-aware Self-training for Low-resource Neural Sequence Labeling. AAAI 2023.

# è‡´è°¢

æˆ‘ä»¬æ„Ÿè°¢é˜¿é‡Œå·´å·´é›†å›¢çš„äººå·¥æ™ºèƒ½å¹³å°ï¼ˆPAIï¼‰å’Œèš‚èšé›†å›¢å¯¹æˆ‘ä»¬å·¥ä½œçš„æ”¯æŒã€‚æˆ‘ä»¬çš„åˆä½œæ¡†æ¶æ˜¯[EasyNLP]ï¼ˆhttps://github.com/alibaba/EasyNLPï¼‰ã€‚æˆ‘ä»¬ä¹Ÿæ„Ÿè°¢æ‰€æœ‰ä¸ºæˆ‘ä»¬çš„å·¥ä½œåšå‡ºè´¡çŒ®çš„å¼€å‘è€…!
